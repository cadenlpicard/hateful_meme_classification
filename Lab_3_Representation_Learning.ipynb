{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1muqgxtW7g6JSQUIn-dFX7IEOwFgybkCs",
      "authorship_tag": "ABX9TyPZNPScU2vsWIQ7+Xo5TNa0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cadenlpicard/hateful_meme_classification/blob/main/Lab_3_Representation_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "e5PwCFk80jKG"
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers pillow pytesseract\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract Text Features\n"
      ],
      "metadata": {
        "id": "uLP-G22Y2TbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "print(\"Importing done\")\n",
        "\n",
        "# Paths to JSONL files\n",
        "data_dir = '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes'\n",
        "train_file = f'{data_dir}/train.jsonl'\n",
        "dev_file = f'{data_dir}/dev_seen.jsonl'\n",
        "\n",
        "# Load JSONL data with a progress bar\n",
        "def load_jsonl(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in tqdm(f, desc=f\"Loading {file_path.split('/')[-1]}\", unit=\"line\"):\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "train_data = load_jsonl(train_file)\n",
        "dev_data = load_jsonl(dev_file)\n",
        "\n",
        "print(\"Data loaded\")\n",
        "\n",
        "# Custom Dataset class to handle on-the-fly encoding\n",
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=128):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data[idx]['text']\n",
        "        label = self.data[idx]['label']\n",
        "        encoding = self.tokenizer(\n",
        "            text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt'\n",
        "        )\n",
        "        return encoding['input_ids'].squeeze(), encoding['attention_mask'].squeeze(), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = AutoModel.from_pretrained(model_name)\n",
        "bert_model.eval()\n",
        "\n",
        "print(\"Tokenizer and model loaded\")\n",
        "\n",
        "# Dataset and DataLoader creation\n",
        "batch_size = 500  # Adjust based on available memory\n",
        "train_dataset = MemeDataset(train_data, tokenizer)\n",
        "dev_dataset = MemeDataset(dev_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(\"Dataloaders created\")\n",
        "\n",
        "# Feature extraction with batch processing and progress tracking\n",
        "def extract_features(data_loader, model, save_path=None):\n",
        "    all_text_features = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=\"Extracting text features\", unit=\"batch\"):\n",
        "            input_ids, attention_mask, _ = [x.to(device) for x in batch]\n",
        "            batch_features = model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
        "            all_text_features.append(batch_features.cpu())\n",
        "\n",
        "    all_text_features = torch.cat(all_text_features, dim=0)\n",
        "    if save_path:\n",
        "        np.save(save_path, all_text_features.numpy())\n",
        "        print(f\"Text features saved to {save_path}\")\n",
        "\n",
        "print(\"Starting feature extraction\")\n",
        "extract_features(train_loader, bert_model, save_path='/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/train_text_features.npy')\n",
        "extract_features(dev_loader, bert_model, save_path='/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/dev_text_features.npy')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BPl9dhM686tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create text classifier, model, and evaluate"
      ],
      "metadata": {
        "id": "iFlfYeEC2ZXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# Load precomputed text features and labels\n",
        "train_text_features = np.load('/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/train_text_features.npy')  # Load text features\n",
        "train_labels = [entry['label'] for entry in load_jsonl(train_file)]  # Load labels\n",
        "\n",
        "# Convert to tensors\n",
        "train_text_features = torch.tensor(train_text_features, dtype=torch.float32)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.float32)\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = 32  # Define your batch size\n",
        "train_dataset = TensorDataset(train_text_features, train_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the Classifier Model\n",
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(TextClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the classifier\n",
        "input_dim = 768  # BERT base embedding size\n",
        "hidden_dim = 128  # Adjustable hyperparameter\n",
        "output_dim = 1    # Binary classification\n",
        "classifier = TextClassifier(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=1e-3)\n",
        "\n",
        "# Initialize an empty list to store evaluation metrics for each epoch\n",
        "epoch_results = []\n",
        "\n",
        "# Training and evaluation\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    classifier.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Training phase\n",
        "    for embeddings, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1} Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier(embeddings)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Training Loss: {epoch_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # Evaluation phase\n",
        "    classifier.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    # Load and process dev set text features as done with the training set\n",
        "    dev_text_features = np.load('/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/dev_text_features.npy')  # Load dev features\n",
        "    dev_labels = [entry['label'] for entry in load_jsonl(dev_file)]\n",
        "\n",
        "    # Convert dev data to tensors\n",
        "    dev_text_features = torch.tensor(dev_text_features, dtype=torch.float32)\n",
        "    dev_labels = torch.tensor(dev_labels, dtype=torch.float32)\n",
        "    dev_dataset = TensorDataset(dev_text_features, dev_labels)\n",
        "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for embeddings, labels in tqdm(dev_loader, desc=f\"Epoch {epoch + 1} Evaluation\"):\n",
        "            outputs = classifier(embeddings)\n",
        "            preds = (torch.sigmoid(outputs.squeeze()) > 0.5).float()\n",
        "\n",
        "            all_preds.extend(preds.numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate metrics for the current epoch\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    auc_roc = roc_auc_score(all_labels, all_preds)\n",
        "\n",
        "    # Append results to epoch_results list\n",
        "    epoch_results.append({\n",
        "        \"Epoch\": epoch + 1,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1,\n",
        "        \"AUC-ROC\": auc_roc\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} - Dev Set Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
        "\n",
        "# Convert epoch_results to a DataFrame for tabular display\n",
        "results_df = pd.DataFrame(epoch_results)\n",
        "print(\"\\nSummary Table of Evaluation Outcomes\")\n",
        "print(results_df)\n",
        "\n",
        "# Define the file path where you want to save the model\n",
        "model_save_path = '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/text_classifier_model.pth'\n",
        "\n",
        "# Save the model's state dictionary\n",
        "torch.save(classifier.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model saved to '{model_save_path}'\")\n"
      ],
      "metadata": {
        "id": "uW_iuR8npYmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Average size of images and delete large images"
      ],
      "metadata": {
        "id": "mltflYIaj126"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to images\n",
        "image_dir = '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/img'\n",
        "\n",
        "# Get sizes of all image files in the directory\n",
        "image_sizes = []\n",
        "for filename in os.listdir(image_dir):\n",
        "    if filename.endswith(('.jpg', '.png')):  # Filter image files\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        file_size = os.path.getsize(file_path)  # File size in bytes\n",
        "        image_sizes.append(file_size)\n",
        "\n",
        "# Convert to numpy array for easy calculation\n",
        "image_sizes = np.array(image_sizes)\n",
        "\n",
        "# Calculate statistics\n",
        "average_size = np.mean(image_sizes)\n",
        "min_size = np.min(image_sizes)\n",
        "max_size = np.max(image_sizes)\n",
        "median_size = np.median(image_sizes)\n",
        "\n",
        "# Display results\n",
        "print(f\"Average file size: {average_size / 1024:.2f} KB\")\n",
        "print(f\"Minimum file size: {min_size / 1024:.2f} KB\")\n",
        "print(f\"Maximum file size: {max_size / 1024:.2f} KB\")\n",
        "print(f\"Median file size: {median_size / 1024:.2f} KB\")\n",
        "\n",
        "\n",
        "# Plot the distribution of image sizes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(image_sizes, bins=30, edgecolor='black')\n",
        "plt.title(\"Distribution of Image File Sizes\")\n",
        "plt.xlabel(\"File Size (KB)\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Set the size threshold (in KB)\n",
        "size_threshold_kb = average_size / 1024\n",
        "\n",
        "# Loop through files and delete those larger than the threshold\n",
        "for filename in os.listdir(image_dir):\n",
        "    if filename.endswith(('.jpg', '.png')):  # Filter for image files\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        file_size_kb = os.path.getsize(file_path) / 1024  # Convert size to KB\n",
        "\n",
        "        if file_size_kb > size_threshold_kb:\n",
        "            os.remove(file_path)  # Delete the file\n",
        "            print(f\"Deleted {filename} ({file_size_kb:.2f} KB)\")\n",
        "\n",
        "print(\"Deletion complete.\")\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kqfRQBruiDCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Process and Extract Features from Images files"
      ],
      "metadata": {
        "id": "CI4bp2_92_RO"
      }
    },
    {
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Path to images\n",
        "image_dir = '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/img'\n",
        "\n",
        "# Image preprocessing\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Custom Dataset class to handle image loading and preprocessing\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        file_size_kb = os.path.getsize(img_path) / 1024  # File size in KB\n",
        "        return img, self.image_files[idx], file_size_kb\n",
        "\n",
        "# Load ResNet model, move to GPU, and set to evaluation mode\n",
        "resnet_model = torchvision.models.resnet50(pretrained=True).to(device)\n",
        "resnet_model.eval()\n",
        "\n",
        "# Set maximum batch size in MB\n",
        "max_batch_size_kb = 150 * 1024  # 150MB in KB\n",
        "\n",
        "# Create an instance of the dataset\n",
        "dataset = ImageDataset(image_dir=image_dir, transform=preprocess)\n",
        "\n",
        "# Extract features in dynamic batches and store them\n",
        "image_features = {}\n",
        "with torch.no_grad():\n",
        "    batch_images, batch_filenames = [], []\n",
        "    cumulative_size_kb = 0  # Track cumulative batch size in KB\n",
        "\n",
        "    for img, filename, file_size_kb in tqdm(dataset, desc=\"Extracting image features\"):\n",
        "        # Add image to batch if within size limit\n",
        "        if cumulative_size_kb + file_size_kb <= max_batch_size_kb:\n",
        "            batch_images.append(img)\n",
        "            batch_filenames.append(filename)\n",
        "            cumulative_size_kb += file_size_kb\n",
        "        else:\n",
        "            # Process current batch\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Stack images into a single tensor batch and move to device\n",
        "            batch_tensor = torch.stack(batch_images).to(device)\n",
        "\n",
        "            # Extract features\n",
        "            features = resnet_model(batch_tensor)\n",
        "\n",
        "            # Move features back to CPU and store with filenames\n",
        "            for i, fname in enumerate(batch_filenames):\n",
        "                image_features[fname] = features[i].cpu().numpy()\n",
        "\n",
        "            # Display batch metrics\n",
        "            batch_time = time.time() - start_time\n",
        "            print(f\"Processed batch of size {cumulative_size_kb / 1024:.2f} MB in {batch_time:.2f}s\")\n",
        "\n",
        "            # Reset batch accumulators\n",
        "            batch_images, batch_filenames = [img], [filename]\n",
        "            cumulative_size_kb = file_size_kb\n",
        "\n",
        "    # Process any remaining images in the last batch\n",
        "    if batch_images:\n",
        "        batch_tensor = torch.stack(batch_images).to(device)\n",
        "        features = resnet_model(batch_tensor)\n",
        "        for i, fname in enumerate(batch_filenames):\n",
        "            image_features[fname] = features[i].cpu().numpy()\n",
        "        print(f\"Processed final batch of size {cumulative_size_kb / 1024:.2f} MB\")\n",
        "\n",
        "# Save features to a .npy file\n",
        "np.save('/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/image_features.npy', image_features)\n",
        "print(\"Image features saved to 'image_features.npy'\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "XjXCsjtbp-bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load feature vectors and Build Classfier"
      ],
      "metadata": {
        "id": "DzVvZfI9qw_n"
      }
    },
    {
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "from tqdm import tqdm  # Import tqdm for progress bars\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load image features\n",
        "image_features = np.load('/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/image_features.npy', allow_pickle=True).item()\n",
        "data_dir = '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes'\n",
        "train_file = f'{data_dir}/train.jsonl'\n",
        "dev_file = f'{data_dir}/dev_seen.jsonl'\n",
        "\n",
        "def load_jsonl(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return [json.loads(line) for line in f]\n",
        "\n",
        "# Load JSONL data and labels\n",
        "def load_data_and_labels(file_path):\n",
        "    data = load_jsonl(file_path)\n",
        "    image_filenames = [entry['img'] for entry in data]\n",
        "    labels = [entry['label'] for entry in data]\n",
        "    return image_filenames, labels\n",
        "\n",
        "train_filenames, train_labels = load_data_and_labels(train_file)\n",
        "dev_filenames, dev_labels = load_data_and_labels(dev_file)\n",
        "\n",
        "def create_image_dataset(filenames, labels, image_features):\n",
        "    filtered_filenames, filtered_labels = [], []\n",
        "    for filename, label in zip(filenames, labels):\n",
        "        key = filename.split('/')[-1]\n",
        "        if key in image_features:\n",
        "            filtered_filenames.append(filename)\n",
        "            filtered_labels.append(label)\n",
        "\n",
        "    image_vectors = [image_features[filename.split('/')[-1]] for filename in filtered_filenames]\n",
        "    image_tensor = torch.tensor(image_vectors, dtype=torch.float32)\n",
        "    labels_tensor = torch.tensor(filtered_labels, dtype=torch.long)\n",
        "    dataset = TensorDataset(image_tensor, labels_tensor)\n",
        "    return dataset\n",
        "\n",
        "train_dataset = create_image_dataset(train_filenames, train_labels, image_features)\n",
        "dev_dataset = create_image_dataset(dev_filenames, dev_labels, image_features)\n",
        "\n",
        "# Model definition\n",
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(ImageClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the classifier and move to GPU\n",
        "input_dim = 1000  # Adjust to match the dimensionality of the image features\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "classifier = ImageClassifier(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=1e-3)\n",
        "\n",
        "# Set maximum batch size by memory limit (150MB in KB)\n",
        "max_batch_size_kb = 150 * 1024  # 150 MB\n",
        "\n",
        "# Helper function to process batches by cumulative memory limit\n",
        "def process_batches(dataset):\n",
        "    cumulative_size_kb = 0\n",
        "    batch_data, batch_labels = [], []\n",
        "    data_loader = []\n",
        "\n",
        "    for features, label in dataset:\n",
        "        feature_size_kb = features.numel() * 4 / 1024  # Assuming float32 (4 bytes per element)\n",
        "\n",
        "        if cumulative_size_kb + feature_size_kb <= max_batch_size_kb:\n",
        "            batch_data.append(features)\n",
        "            batch_labels.append(label)\n",
        "            cumulative_size_kb += feature_size_kb\n",
        "        else:\n",
        "            data_loader.append((torch.stack(batch_data), torch.tensor(batch_labels)))\n",
        "            batch_data, batch_labels = [features], [label]\n",
        "            cumulative_size_kb = feature_size_kb\n",
        "\n",
        "    if batch_data:\n",
        "        data_loader.append((torch.stack(batch_data), torch.tensor(batch_labels)))\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "# Training and evaluation\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    classifier.train()\n",
        "    epoch_loss = 0\n",
        "    train_batches = process_batches(train_dataset)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs} - Training:\")\n",
        "    for batch_idx, (features, labels) in enumerate(tqdm(train_batches, desc=f\"Training Batch Progress\")):\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier(features)\n",
        "        loss = criterion(outputs.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Display batch-level loss\n",
        "        print(f\"Batch {batch_idx + 1}/{len(train_batches)} - Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(train_batches)\n",
        "    print(f\"Epoch {epoch + 1} - Average Training Loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "    # Evaluation on the development set\n",
        "    classifier.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    dev_batches = process_batches(dev_dataset)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs} - Evaluation:\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (features, labels) in enumerate(tqdm(dev_batches, desc=\"Evaluation Batch Progress\")):\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = classifier(features)\n",
        "            preds = torch.sigmoid(outputs.squeeze()) > 0.5\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    auc_roc = roc_auc_score(all_labels, all_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} - Dev Set Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(classifier.state_dict(), '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/image_classifier_model.pth')\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ORkUjC66rQqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multimodal Classification - Early Fusion"
      ],
      "metadata": {
        "id": "Ua_hOLhVJFmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load image features and text features\n",
        "image_features = np.load('/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/image_features.npy', allow_pickle=True).item()\n",
        "train_text_features = np.load('/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/train_text_features.npy')\n",
        "dev_text_features = np.load('/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/dev_text_features.npy')\n",
        "\n",
        "# Path to JSONL files with labels (modify paths as necessary)\n",
        "train_file = '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/train.jsonl'\n",
        "dev_file = '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/dev_seen.jsonl'\n",
        "\n",
        "# Function to load JSONL data and labels\n",
        "def load_labels(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = [json.loads(line) for line in f]\n",
        "    labels = [entry['label'] for entry in data]\n",
        "    return labels\n",
        "\n",
        "# Load labels\n",
        "train_labels = load_labels(train_file)\n",
        "dev_labels = load_labels(dev_file)\n",
        "\n",
        "# Prepare training and dev datasets with feature-level fusion\n",
        "def create_fusion_dataset(image_features, text_features, labels):\n",
        "    # Assumes image_features is a dict with filename keys, and text_features is an array aligned with the labels\n",
        "    combined_features = []\n",
        "    for idx, (filename, label) in enumerate(zip(image_features.keys(), labels)):\n",
        "        image_feature = image_features[filename]\n",
        "        text_feature = text_features[idx]\n",
        "        fused_feature = np.concatenate((image_feature, text_feature))  # Feature-level fusion by concatenation\n",
        "        combined_features.append((fused_feature, label))\n",
        "\n",
        "    # Convert to tensors\n",
        "    feature_tensors = torch.tensor([f[0] for f in combined_features], dtype=torch.float32)\n",
        "    label_tensors = torch.tensor([f[1] for f in combined_features], dtype=torch.long)\n",
        "    return TensorDataset(feature_tensors, label_tensors)\n",
        "\n",
        "train_dataset = create_fusion_dataset(image_features, train_text_features, train_labels)\n",
        "dev_dataset = create_fusion_dataset(image_features, dev_text_features, dev_labels)\n",
        "\n",
        "# Data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the multimodal classifier model\n",
        "class MultimodalClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MultimodalClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "input_dim = train_dataset[0][0].shape[0]  # Dimension of concatenated image and text features\n",
        "hidden_dim = 128\n",
        "output_dim = 1  # Binary classification\n",
        "model = MultimodalClassifier(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training and evaluation loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for features, labels in train_loader:\n",
        "        features, labels = features.to(device), labels.to(device, dtype=torch.float32)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for features, labels in dev_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features).squeeze()\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    auc_roc = roc_auc_score(all_labels, all_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"Dev Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, AUC-ROC: {auc_roc:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/multimodal_classifier_model.pth')\n",
        "print(\"Model saved to 'multimodal_classifier_model.pth'\")\n"
      ],
      "metadata": {
        "id": "mx_3eBTi3Jp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multimodal Classification - Late Fusion"
      ],
      "metadata": {
        "id": "nxE1jN5c3Wbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load image features and text features\n",
        "image_features = np.load('/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/image_features.npy', allow_pickle=True).item()\n",
        "train_text_features = np.load('/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/train_text_features.npy')\n",
        "dev_text_features = np.load('/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/dev_text_features.npy')\n",
        "\n",
        "# Path to JSONL files with labels\n",
        "train_file = '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/train.jsonl'\n",
        "dev_file = '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/dev_seen.jsonl'\n",
        "\n",
        "# Function to load labels\n",
        "def load_labels(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = [json.loads(line) for line in f]\n",
        "    labels = [entry['label'] for entry in data]\n",
        "    return labels\n",
        "\n",
        "# Load labels\n",
        "train_labels = load_labels(train_file)\n",
        "dev_labels = load_labels(dev_file)\n",
        "\n",
        "# Prepare individual datasets for image and text features\n",
        "def create_dataset(features, labels):\n",
        "    # Ensure features and labels have the same length\n",
        "    min_len = min(len(features), len(labels))\n",
        "    features = features[:min_len]\n",
        "    labels = labels[:min_len]\n",
        "\n",
        "    feature_tensors = torch.tensor(features, dtype=torch.float32)\n",
        "    label_tensors = torch.tensor(labels, dtype=torch.long)\n",
        "    return TensorDataset(feature_tensors, label_tensors)\n",
        "\n",
        "train_image_features = [image_features[filename] for filename in image_features.keys()]\n",
        "dev_image_features = [image_features[filename] for filename in image_features.keys()]\n",
        "\n",
        "train_image_dataset = create_dataset(train_image_features, train_labels)\n",
        "dev_image_dataset = create_dataset(dev_image_features, dev_labels)\n",
        "\n",
        "train_text_dataset = create_dataset(train_text_features, train_labels)\n",
        "dev_text_dataset = create_dataset(dev_text_features, dev_labels)\n",
        "\n",
        "# Data loaders\n",
        "batch_size = 32\n",
        "train_image_loader = DataLoader(train_image_dataset, batch_size=batch_size, shuffle=True)\n",
        "dev_image_loader = DataLoader(dev_image_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_text_loader = DataLoader(train_text_dataset, batch_size=batch_size, shuffle=True)\n",
        "dev_text_loader = DataLoader(dev_text_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define individual classifiers\n",
        "class SingleModalClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SingleModalClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize image and text classifiers\n",
        "input_dim_image = train_image_features[0].shape[0]\n",
        "input_dim_text = train_text_features.shape[1]  # Assuming train_text_features is a 2D array\n",
        "hidden_dim = 128\n",
        "output_dim = 1  # Binary classification\n",
        "\n",
        "image_classifier = SingleModalClassifier(input_dim_image, hidden_dim, output_dim).to(device)\n",
        "text_classifier = SingleModalClassifier(input_dim_text, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "image_optimizer = optim.Adam(image_classifier.parameters(), lr=1e-3)\n",
        "text_optimizer = optim.Adam(text_classifier.parameters(), lr=1e-3)\n",
        "\n",
        "# Training and evaluation loop\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    image_classifier.train()\n",
        "    text_classifier.train()\n",
        "\n",
        "    total_image_loss, total_text_loss = 0, 0\n",
        "\n",
        "    # Train image classifier\n",
        "    for features, labels in train_image_loader:\n",
        "        features, labels = features.to(device), labels.to(device, dtype=torch.float32)\n",
        "\n",
        "        image_optimizer.zero_grad()\n",
        "        outputs = image_classifier(features).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        image_optimizer.step()\n",
        "        total_image_loss += loss.item()\n",
        "\n",
        "    avg_image_loss = total_image_loss / len(train_image_loader)\n",
        "\n",
        "    # Train text classifier\n",
        "    for features, labels in train_text_loader:\n",
        "        features, labels = features.to(device), labels.to(device, dtype=torch.float32)\n",
        "\n",
        "        text_optimizer.zero_grad()\n",
        "        outputs = text_classifier(features).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        text_optimizer.step()\n",
        "        total_text_loss += loss.item()\n",
        "\n",
        "    avg_text_loss = total_text_loss / len(train_text_loader)\n",
        "\n",
        "    # Evaluation\n",
        "    image_classifier.eval()\n",
        "    text_classifier.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (image_features, labels), (text_features, _) in zip(dev_image_loader, dev_text_loader):\n",
        "            image_features, text_features, labels = image_features.to(device), text_features.to(device), labels.to(device)\n",
        "\n",
        "            # Get predictions from each classifier\n",
        "            image_outputs = torch.sigmoid(image_classifier(image_features).squeeze())\n",
        "            text_outputs = torch.sigmoid(text_classifier(text_features).squeeze())\n",
        "\n",
        "            # Decision fusion (average the predictions)\n",
        "            combined_outputs = (image_outputs + text_outputs) / 2\n",
        "            preds = combined_outputs > 0.5\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    auc_roc = roc_auc_score(all_labels, all_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    print(f\"Image Training Loss: {avg_image_loss:.4f}, Text Training Loss: {avg_text_loss:.4f}\")\n",
        "    print(f\"Dev Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, AUC-ROC: {auc_roc:.4f}\")\n",
        "\n",
        "# Save the models\n",
        "torch.save(image_classifier.state_dict(), '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/multi_modal_late_fusion_image_classifier_model.pth')\n",
        "torch.save(text_classifier.state_dict(), '/content/drive/MyDrive/Machine Learning/Hateful Meme Dataset/hateful_memes/multi_modal_late_fusion_text_classifier_model.pth')\n",
        "print(\"Models saved.\")\n"
      ],
      "metadata": {
        "id": "AJL11eHesJaj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}